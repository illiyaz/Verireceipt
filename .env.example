# LLM Configuration for Document Classification
# Provider: "ollama" (local), "openai" (cloud), or "none" (disabled)
LLM_PROVIDER=ollama

# Ollama Settings (for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI Settings (for cloud API)
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# Common Settings
LLM_MAX_TOKENS=300
LLM_TEMPERATURE=0.0
LLM_TIMEOUT=30
